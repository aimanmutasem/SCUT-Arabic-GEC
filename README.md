# SCUT-Arabic-GEC
Unsupervised Arabic GEC model based on convolutional sequence-to-sequence learning called SCUT AGEC. In this work, we have proposed an unsupervised method to generate a large-scale synthetic dataset based on confusion function to increase the amount of training set. The generated synthetic dataset consists of 19,152, 950 million words to train the model. Then, we introduce a convolution model as Neural Machine Translation (NMT) task for Arabic Grammar Error Correction (AGEC) because Convolutional Natural Networks (CNN) consider feature extraction and classification as one joint task and it is better to capture the local context. Furthermore, it is easy to obtain long-term dependencies by staking the convolutional layers. Besides, we propose a fine-tuning model by returning the model using an authentic dataset to improve the performance and smoothing results. 
